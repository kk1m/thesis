\chapter{Conclusion}

This paper presents an investigation of the issues involved in distributed and parallel machine learning of IoT data streams. We follow a systematic experimental principle that develop two end-to-end workflows that consists of two sets of algorithms. We investigate the dominating factors of parallelism at the level of data operations and transformations that are common to a wide range of algorithms, hence the observations are general applicable, not specific to the algorithms examined. Based on the observations and experiences, we advocate the practices of (1) the development principle of having multiple models to analyze the same datasets to produce complementary insights of the data; (2) reducing data shuffling by means of partition methods and choice of transformation; (3) monitoring at run-time the intermediate data partitions that are subject to re-partition; (4) increasing the parallelism by adding more computing cores is not necesssarily improve the performance nor scalability. The bottleneck lies on the internal dependent iterations of algorithms. 

In this work, the tuning and optimization of the workflow is still manully deviced. Our future research focues on building a middleware layer that encapsulates the monitoring and re-parition so that they are automatically integrated to scale a workflow. 
