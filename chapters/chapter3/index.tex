\chapter{Data Preprocessing}

\section{Data Preprocessing}\label{sec:dataprocessing}

Data preprocessing helps to assess the correlation between features. The purpose is to identify out which of over 350 features are redundant that should be further merged for dimensional reduction. In fact, the gathered time series have different sampling intervals. Also these time series have missing data. Therefore the data preprocessing first deals with alignments of time series. We apply two approaches to aggregating data by features. 

\begin{enumerate}
	\item Averaging the values at every time stamp. At eatch time stamp, there are multiple data records for each feature from different devices. This approach first performs alignment of all-time series of the same feature by time stamps. If a time stamp has no readings from any devices, the missing value is filled as zero. Then the average value is taken for each feature at each timestamp. A sample plot of the dataset in Figure~\ref{Fig:sample-plot} after the alignment is shown in Figure~\ref{Fig:alignment-timeseries}.
	
	\begin{figure}
		\centering		
		\includegraphics[keepaspectratio,height=3in, width=3in]{./figures/avgts}
		\caption{ The original 9 time series in Figure~\ref{Fig:sample-plot} are aligned into 3 time series, one for each feature that is generated by averaging the readings per time stamps from 3 devices.}
		\label{Fig:alignment-timeseries}
	\end{figure}
	
	\item Concatenating the time series from different devices sequentially. This approach first creates a list of all devices. Then time series is created for each feature by concatenating the time series of the devices by respecting the order of that list. This is achieved by creating an artificial and longer timeline of readings. Again, empty readings are filled by zero. The order in which the time series is appended must stay consistent accross different features. Figure~\ref{Fig:alignment-concatenate} plots the concatenated time series of Figure~\ref{Fig:sample-plot}.
	
	\begin{figure}
		\begin{center}
		\includegraphics[keepaspectratio,height=4in, width=3.5in]{./figures/concatts}
		\caption{The original 9 time series in Figure~\ref{Fig:sample-plot} are aligned into 3 time series.  The 3 devices of the same feature are appended one after the other. Device one has the time serieis from the data points ranging between 0 to 60 seconds; device 2's values range between 65 to 125 seconds; and devices 3' values are from 130 to 190 seconds respectively.}
		\label{Fig:alignment-concatenate}
		\end{center}
	\end{figure}
	
\end{enumerate}


\begin{figure}
	\centering
	\includegraphics[keepaspectratio,height=3in, width=3in]{./figures/binned10ts}
	\caption{Times series from Figure~\ref{Fig:alignment-concatenate} after applying binning by average on a window of 10 seconds}
	\label{Fig:binning-10}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[keepaspectratio,height=3in, width=3in]{./figures/binned20ts}
	\caption{Times series from Figure 4 after applying binning by average on a window of 20 seconds}
	\label{Fig:binning-20}
\end{figure}


The approach of averaging preserves less information in contrast to the concatenating method. The reason behind this assumption is that the dataset is extremely sparse, hence taking the average of readings to generate a final value per time stamp does not provide an accurate value for this time series. The approach of concatenation preserves more information because the readings at each timestamp are preserved. Consequently, we create much larger spans of time series as appending one after the other. This leads to our subsequent quantization process. 

The process of quantization maps input values from a large set to the output values in a smaller set. In this paper, we apply the data binning or bucketing technique that takes a set of data points falling in a window of time stamps and reduces them into a single value. The single value is the average value of data points of multiple time stamps.  We perform this binning technique across all the time series, thus reduce the length and the dimensionality of the concatenated data.  

The window size is a tunable parameter as it becomes a factor for trade-off between the processing time and the information retention. Figure~\ref{Fig:binning-10} and Figure~\ref{Fig:binning-20} show the time series after the binning technique for the window size of 10 seconds and 20 seconds respectively. 
