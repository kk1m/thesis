\begin{abstract}
\textbf{Context:} Connected devices within IoT is a source of generating big data. The data measured from devices consists of large number of features from hundreds to thousands.  Analyzing these features is both data and computing intensive. Distributed and parallel processing frameworks such as Apache Spark provide in-memory processing technologies to design feature analytic workflows. However, algorithms for discovering data patterns and trends over time series are not necessarily ready to cooperate issues such as data partition, data shuffling that rise from  distribution and parallelism. \textbf{Aim:} This work aims to explore the relation between algorithm characteristics and parallelisms as well as the effects on clustering results and the system performance. \textbf{Method:} We develop system level techniques that address particularly the data partition, load-balancing and data shuffling issues. We apply these techniques to adopt clustering algorithms on distributed parallel computing frameworks.  In the evaluation, we build two workflows that each consists of a clustering algorithm and its corresponding metrics for measuring distances of any two time series data. \textbf{Result:} We demonstrate these system level techniques improve the overall performance by over 50\%. \textbf{Conclusion:} Our distribution and parallel workflows address both algorithmic factors and parallelism factors to improve accuracy and performance of processing big time series data of connected devices.
\end{abstract}